#!/usr/bin/env python

# plot_expression_across_chromosomes_direct.py by Wayne Decatur
__author__ = "Wayne Decatur" #fomightez on GitHub
__license__ = "MIT"
__version__ = "0.2.0"

#*******************************************************************************
# Written in Python 2.7 to be compatible with Python 3.
#
# PURPOSE: Plot ratio of expression of experimental condition vs. wild-type (or 
# baseline state) for genes in sequential order across chromosomes in the genome. 
# Should serve to highlight regions of deviation characteristic of aneuploidy 
# or segmental duplication/deletion. The idea is you just need to point the 
# script at the raw data files from your quantified RNA-Seq wild-type and 
# experimental replicates and it will automagically handle the combining of that
# data and produce a plot showing the expression of genes across the chromosomes
# for your experimental strain relative the wild-type. (If you've already 
# combined or somehow summarized your level metric for both your wild-type 
# and experimental replicates, then you'll want my related my script 
# `plot_expression_across_chromosomes.py`.)
# plot_expression_across_chromosomes_direct.py  script requires three files: 
# 1. a file of a genome annotation format in order to parse the locations of 
# genes and (approximate) length of chromosomes; 2. a file of resulting from 
# quantification of a wild-type sample; and 3. a file of resulting from 
# quantification of an experimental sample. You can have quantified data for 
# more than one of the wild-type and experimental samples, i.e., replicates and 
# that is always the preferred situation for downstream analyses; the script 
# will determine and subsequently use the mean of your expression level metric. 
# By default, the script assumes the data is quanitified by Salmon and uses 
# the TPM as the level metric, i.e., the fourth column in the `quant.sf` 
# tab-separated values files generated by Salmon; however, there is an option to 
# specify which column in the data files you want to use so you can use other 
# sources of expression level metrics, such as counts from HT-Seq, abundances in 
# `abundances.tsv` from kallisto, etc.. All the data files must be consistent 
# as you can not choose one column from one and and a different column from 
# another.
#
# There are several optional flags that can be supplied at the time of calling
# the script to control options. These are shown if you invoke with `-help` 
# flag or simply call the script with no additional arguments. Additionally, 
# inside the script there are several `USER ADJUSTABLE VALUES` that can be 
# edited for easy customization.
# Built to be general enough to be easily modified.
# The plotting approach and other aspects borrow from Brent Pedersen's awesome
# `manhattan-plot.py` script at the link below:
# https://github.com/brentp/bio-playground/blob/master/plots/manhattan-plot.py
# This script should produce a plot similar to a combination of Brent Pedersen's
# `manhattan-plot`and Figure 5B from Thorburn et al. 2013 (PMID: 23468524), see 
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3639041/
# Other than allowing direct use of data files produced as output by Salmon or 
# other RNA-Seq quantification software, this "direct" version is otherwise 
# identical to my script `plot_expression_across_chromosomes.py`, and so you 
# should see the documentation for that for full details.
#
#
#
#
# Dependencies beyond the mostly standard libraries/modules:
# statsmodels, seaborn (although could easily be altered to make unneeded)
#
#
# VERSION HISTORY:
# v.0.1. basic working version
# v.0.2. refactored early part to speed up.
#
# to do:
# 
#
#
#
# TO RUN:
# Example,
# Enter on the command line of your terminal, the line
#-----------------------------------
# python plot_expression_across_chromosomes_direct.py genome_annotation.gtf data1.quant.sf data2.quant.sf
#-----------------------------------
#
#
#*******************************************************************************
#


#*******************************************************************************
##################################
#  USER ADJUSTABLE VALUES        #

##################################
#

# `genome_annotation_fields` to match your genome annotation source data. You'll 
# most likely only need one of these. 
genome_annotation_fields_for_gtf = ("seqname", "source", "feature type", "start", 
    "end", "score", "strand", "frame", "attribute")
genome_annotation_fields_for_gff = ("seqname", "source", "feature type", "start", 
    "end", "score", "strand", "frame", "group")
genome_annotation_fields_for_bed = ("chrom", "chromStart", "chromEnd", "name", 
    "score", "strand", "thickStart", "thickEnd", "itemRgb", "blockCount", 
    "blockSizes", "blockStarts")
column_types_for_gff  = {"seqname":'category',
                "source":'object',
                "feature type":'object',
                "start":'int64',
                "end":'int64',
                "score":'object',
                "strand":'object',
                "frame":'object',
                "group":'object',
               }
column_types_for_gtf = {"seqname":'category',
                "source":'object',
                "feature type":'object',
                "start":'int64',
                "end":'int64',
                "score":'object',
                "strand":'object',
                "frame":'object',
                "attribute":'object',
               }

suffix_for_saving_result = "_across_chr.png"

title_prefix = "Expression across " # Change to `None` to suppress title

limit_before_rotate = 3 # upper limit of max length of chromosome or scaffold 
# names before x axis labels are all rotated when plotting all genome. Same 
# number will be used as total number of chromosomes (or scaffold) to be 
# plotting before considering length of name again.

y_cutoff = 4 # A limit was added to avoid extreme values compressing the 
# typically important range when log2 used. Adjust that limit here or 
# run with `--no_limits` flag enables. y_cutoff is not used when `no_log` flag 
# used or when values are within +/- this interval.

deviation_factor = 0.25 #measure of degree of discrepancy to use when suggesting 
# aneuploidy at a chromosome or scaffold level when using `--smooth` flag; 0.5
# seems better but keeping at 0.25 for now to be sure to cast wide net
deviation_fraction = 0.51 #fraction of values for a chromosome or scaffold that 
# need to deviate from baseline by deviation_factor before aneuploidy is 
# suggested when using `--smooth` flag


plot_style = "seaborn" #try also `ggplot`,`default`, `bmh` or `grayscale`; use 
# `print(plt.style.available)` after appropriate imports to see others; 
# illustrated at https://matplotlib.org/examples/style_sheets/style_sheets_reference.html

#colors = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9']
# if using `ggplot` or `seaborn` style as coded in script than it has less than 
# 10 colors in the `CN` group and begins cycling internally back to `C0` when 
# hits `C7`(`C6` for seaborn), etc., & so same colors appear several times in 
# row when cycles again to `C0`. Options to fix current situation:
colors = (['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'xkcd:magenta', 'xkcd:orange', 
    'tab:gray','tab:pink'])  # for use with `seaborn` style
colors = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6'] # for use with ggplot style
colors = (['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'xkcd:orange','tab:pink', 
    'tab:cyan'])  # for use with `ggplot` style
colors = (['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 
    'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']) 
colors = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5'] # for use with seaborn style
colors = (['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'xkcd:magenta'])# w/`seaborn`
# see https://matplotlib.org/users/colors.html for other options


#
#*******************************************************************************
#**********************END USER ADJUSTABLE VARIABLES****************************





















#*******************************************************************************
#*******************************************************************************
###DO NOT EDIT BELOW HERE - ENTER VALUES ABOVE###

import sys
import os
import argparse
import pandas as pd
import numpy as np
from itertools import cycle
import matplotlib # in order to use `matplotlib.use('Agg')`, need this first, see source of next line
matplotlib.use('Agg') # Force matplotlib to not use any Xwindows backend for running on PythonAnywhere. # from https://stackoverflow.com/questions/2801882/generating-a-png-with-matplotlib-when-display-is-undefined after searched error I was getting after upgrading matplolib in my Pythonanywhere account
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.nonparametric.smoothers_lowess import lowess



###---------------------------HELPER FUNCTIONS---------------------------------###


def generate_output_file_name(file_name, suffix):
    '''
    Takes a file name as an argument and returns string for the name of the
    output file. The generated name is based on the original file
    name.

    It also indicates in resulting file name name specific chromsomes or 
    scaffolds if plotting was limited to those.

    Specific example
    ================
    Calling function with
        ("data1.txt", "_across_chr.png")
    returns
        "data1_across_chr.png"
    
    if `limit_to_chrs = ["II","IV"]`,
    Calling function with
        ("data1.txt", "_across_chr.png")
    returns
        "data1_across_chr_II_IV.png"
    '''
    main_part_of_name, file_extension = os.path.splitext(
        file_name) #from http://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python
    if limit_to_chrs:
        main_part_of_suffix, suffix_file_extension = os.path.splitext(
        suffix)
        suffix = main_part_of_suffix + "_" + "_".join(
            limit_to_chrs) + suffix_file_extension 
    return main_part_of_name + suffix



def extract_gene_ids(row):
    '''
    parses out the gene_id from the attributes list in a line in annoation file 
    formatted in Ensembl format, for example Ensembl-formatted yeast genome from 
    ftp://igenome:G3nom3s4u@ussd-ftp.illumina.com/Saccharomyces_cerevisiae/Ensembl/R64-1-1/Saccharomyces_cerevisiae_Ensembl_R64-1-1.tar.gz
    Here the annotation file has been read in as a pandas dataframe and the 
    `attributes` field is in column 9, specified by `row[8]` in the code.
    Using that instead of the column name because not called attribures list
    in the gff format but it has `group` field at same position.

    takes a row of a pandas dataframe derived from an annotation file

    returns a string of the systematic gene id
    '''
    return row[8].split("gene_id")[1].split('"')[1].strip()

def calculate_position(row):
    '''
    takes a row of pandas dataframe derived from an annotaion file & calculates 
    the average position of a gene or feature along the chromosome by taking the
    average of the start and end

    returns an integer
    '''
    return (int(row["start"]) + int(row["end"]))/2



def checkIfRomanNumeral(numeral):
    """
    Controls that the userinput only contains valid roman numerals
    function from praveen's answer at 
    https://stackoverflow.com/questions/20973546/check-if-an-input-is-a-valid-roman-numeral
    """
    numeral = numeral.upper()
    valid_roman_numerals = ["M", "D", "C", "L", "X", "V", "I", "(", ")"]
    valid = True
    for letters in numeral:
        if letters not in valid_roman_numerals:
            #print("Sorry that is not a valid roman numeral")
            valid = False
            break
    return valid

def int_to_roman(input):
    """
    from Paul Winkler's http://code.activestate.com/recipes/81611-roman-numerals/
    (had to reindent; was causing text editor to default to wrong spacing
    otherwise. Plus updated some idioms too.)
    Convert an integer to Roman numerals.

    Examples:
    >>> int_to_roman(0)
    Traceback (most recent call last):
    ValueError: Argument must be between 1 and 3999

    >>> int_to_roman(-1)
    Traceback (most recent call last):
    ValueError: Argument must be between 1 and 3999

    >>> int_to_roman(1.5)
    Traceback (most recent call last):
    TypeError: expected integer, got <type 'float'>

    >>> for i in range(1, 21): print int_to_roman(i)
    ...
    I
    II
    III
    IV
    V
    VI
    VII
    VIII
    IX
    X
    XI
    XII
    XIII
    XIV
    XV
    XVI
    XVII
    XVIII
    XIX
    XX
    >>> print int_to_roman(2000)
    MM
    >>> print int_to_roman(1999)
    MCMXCIX
    """
    if type(input) != type(1):
        raise TypeError ("expected integer, got {0}".format(type(input)))
    if not 0 < input < 4000:
        raise ValueError ("Argument must be between 1 and 3999")
    ints = (1000, 900,  500, 400, 100,  90, 50,  40, 10,  9,   5,  4,   1)
    nums = ('M',  'CM', 'D', 'CD','C', 'XC','L','XL','X','IX','V','IV','I')
    result = ""
    for i,e in enumerate(ints):       #formerly `for i in range(len(ints))`
        count = int(input / e) #formerly `count = int(input / ints[i])`
        result += nums[i] * count
        input -= e * count #formerly `input -= ints[i] * count`
    return result

def roman_to_int_if_possible(input):
    """
    modified from Paul Winkler's roman_to_int at
    http://code.activestate.com/recipes/81611-roman-numerals/
    (had to reindent; was causing text editor to default to wrong spacing
    otherwise. Plus updated some idioms too.)

    Try to convert a roman numeral to an integer. 
    Return original input if not possible.
    """
    #if type(input) != type(""):
    #   raise TypeError, "expected string, got %s" % type(input)
    input = input.upper()
    nums = ['M', 'D', 'C', 'L', 'X', 'V', 'I']
    ints = [1000, 500, 100, 50,  10,  5,   1]
    places = []
    for c in input:
        if not c in nums:
            #raise ValueError, "input is not a valid roman numeral: %s" % input
            return input
    for i,e in enumerate(input):  #formerly `for i in range(len(input)):`
        c = e #formerly `c = input[i]`
        value = ints[nums.index(c)]
        # If the next place holds a larger number, this value is negative.
        try:
            nextvalue = ints[nums.index(input[i +1])]
            if nextvalue > value:
                value *= -1
        except IndexError as e:
            # there is no next place.
            pass
        places.append(value)
    sum = 0
    for n in places: sum += n
    # Easiest test for validity...
    if int_to_roman(sum) == input:
        return sum
    else:
        #raise ValueError, 'input is not a valid roman numeral: %s' % input
        return input
    
def seqname_roman_to_numeric(row):
    '''
    takes a row of pandas dataframe derived from an annotaion file and attempts 
    to convert the seqname value in roman numeral form to a numeric

    returns an integer if able to convert; 
    returns original value if unable to convert
    '''
    return roman_to_int_if_possible(row["seqname"])


def seqname_string_to_numeric(row):
    '''
    takes a row of pandas dataframe derived from an annotaion file and attempts 
    to convert the seqname value in string form to a numeric

    returns an integer if able to convert; 
    returns original value if unable to convert
    '''
    try:
        return int(row["seqname"])
    except ValueError as e:
        return row["seqname"]  

def get_gene_expression(file_list, the_dictionary):
    '''
    takes a list of file and a dictionary and fills in expression information 
    for every gene

    returns the dictionary
    '''
    files_handled = 0
    for the_file in file_list:
        #open file
        files_handled += 1
        with open(the_file , 'r') as file_stream:
            for line in file_stream:
                items = line.split("\t")
                gene = items[0] # for now I am assuming all cases the first column is gene identifier, as it is in Salmon output and HT-Seq output. May have to eventually adjust code back to allow selection for that in addition to the level metric if not the case. Can use the `--columns` code and subsequent handling in `plot_expression_across_chromosomes_direct.py`, if that ever is the case.
                try:
                    float(items[data_column-1])
                except ValueError:
                    #print "Not a float"
                    continue # go to next line in file because maybe this is header line or other malformed data
                if gene not in the_dictionary:
                    the_dictionary[gene] = [float(items[data_column-1]) * 10000] # minus 1 because ask for the column in normal terms and want coverted to zero-indexed for python code; `* 10,000` I have seen used to make working with TPM values more reasonable, and it won't affect anything since ultimately factored out when ratio made
                else:
                    the_dictionary[gene].append(float(items[data_column-1]) * 10000)  # minus 1 because ask for the column in normal terms and want coverted to zero-indexed for python code; `* 10,000` I have seen used to make working with TPM values more reasonable, and it won't affect anything since ultimately factored out when ratio made
    # provide general feedback
    sys.stderr.write("{0} files parsed for expression data for {1} genes...".format(files_handled, len(the_dictionary)))
    return the_dictionary

def deviates_from_baseline(values):
    '''
    Determines if values for a chromosome or scaffold suggest aneuploidy.

    Specifically, the function assess if a substantial fraction of lowess ys 
    for a chromosome differ from baseline, i.e., are a good fraction greater 
    than 0.25 or below 0.25 whenlog2 is used (default) or greater than 1.25 and
    less than 0.75 when no_log.
    This degree can be adjusted with deviation_factor setting under 
    "USER ADJUSTABLE VALUES". Default setting provided in script is 0.25.

    Returns a boolean value indicating if chromosome or scaffold shows 
    aneuploidy based on a simplistic assessment. Your mileage may vary.
    '''
    baseline = 1.0 if no_log else 0.0
    return float(len([value for value in values if not (baseline
         - deviation_factor < value < baseline
         + deviation_factor)])) / float(len(values)) \
    > deviation_fraction


###--------------------------END OF HELPER FUNCTIONS---------------------------###
###--------------------------END OF HELPER FUNCTIONS---------------------------###














#*******************************************************************************
###-----------------for parsing command line arguments-----------------------###
parser = argparse.ArgumentParser(prog='plot_expression_across_chromosomes_direct.py',
    description="plot_expression_across_chromosomes_direct.py uses raw \
    quantified RNA-seq data (defaults to Salmon-generated data) to plot a ratio of \
    expression values across chromosomes or scaffolds of a genome to highlight \
    regions of deviation. Besides the options listed here, there are several \
    `USER ADJUSTABLE VALUES` inside the script that can be edited for easy \
    customization. A similar plot is called a Manhattan plot and this \
    implementation borrows the plotting approach and some of the features from \
    Brent Pedersen's awesome `manhattan-plot.py` script.       \
    **** Script by Wayne Decatur   \
    (fomightez @ github) ***")

parser.add_argument("annotation", help="Name of file containing the genome \
    annotation. REQUIRED. This is needed to determine the order of individual \
    data points along the chromosome and how to display the data across \
    chromosomes or scaffolds.", 
    type=argparse.FileType('r'), metavar="ANNOTATION_FILE")
parser.add_argument("data_files_list", help="Names of files containing the data \
    to plot, such as or RPKM, etc. in tab-delimited form for at least one \
    wild-type(baseline) sample and one experimental sample. AT LEAST TWO TOTAL \
    REQUIRED. Assumed that it is quantified by Salmon; specify column flag if \
    level not in fourth column. Wild-type(baseline) samples are to be listed \
    first. If number of files provided is even and no `--wt_num` provided then \
    first half is considered wild-type set and the last half considered \
    experimental set. \
    Use `--wt_num` flag to specify number of wild-type base-line samples if \
    not split evenly or total number of data samples are an odd number.", 
    type=str, nargs='+', metavar="DATA_FILES")
parser.add_argument('-wn', '--wt_num', action='store', type=int, 
    help="use this flag followed by an integer to specify how many of the \
    initial data files provided are \
    wild-type(baseline) when samples not split evenly (e.g., `--wt_num 2` in case of 2 wild-type and 4 experimental replicates) \
    or using and odd number of total data files. In the example where not split \
    evenly, flag to add to command call would be `--wt_num 2`. ")
parser.add_argument('-col', '--column', action='store', type=int, 
    default= '4', help="column for expression metric in data file. Assumes a \
    value of four to match fourth tab-separated column in Salmon-quantified \
    RNA-Seq data.") 
parser.add_argument("-l", "--lines",help=
    "add this flag to plot the expression level ratio value as lines \
    extending from the x-axis rather than points in space. (The resulting \
    aesthetic may resemble a city skyline for which the `manhattan plot` is \
    named.)",
    action="store_true")
parser.add_argument('-chr', '--chrs', action='store', type=str, 
    help="use this flag to limit plotting of the data to particular \
    chromosomes or scaffolds you specify immediately following this flag. \
    Separate the chromosome or scaffold identifiers by commas, without spaces. \
    Example use in a command is `--chrs I,IV,XVI`. \
    Default when this optional flag is not called is to plot that data for all \
    chromosomes or scaffolds. ") # based on
    # https://stackoverflow.com/questions/15753701/argparse-option-for-passing-a-list-as-option
parser.add_argument("-nl", "--no_log",help=
    "add this flag to keep the expression level ratio to be plotted in the \
    common base 10 instead of converting to log2.",
    action="store_true")
parser.add_argument("-nlim", "--no_limits",help=
    "add this flag to not impose a limit of above and below {} in plot window \
    when converting to log2. The cutoff can also be adjusted under \
    `user-adjustable settings` in the script. Issuing this flag has no effect \
     if all values are within +/- the cutoff interval or `--no_log` is used."
    .format(y_cutoff),
    action="store_true")
parser.add_argument("-s", "--smooth",help=
    "add this flag to display a smoothing curve fit to the data points \
    (LOWESS) on a per chromosome basis. This option can enhance visualization \
    of deviations characteristic of aneuploidy and copy number variation across \
    the genome, both within and between chromosomes. Additionally, a \
    simplistically-based assesment will be made for aneuploidy at the \
    chromosome or scaffold level and a notice will be made as the program is \
    running if aneuploidy at the chromosome or scaffold level seems indicated \
    by this simple metric. Further examination is warranted regardless of \
    the result this automated assessment.",
    action="store_true")
parser.add_argument('-ed', '--exp_desig', action='store', type=str, 
    default= 'experimental', help="Allows changing the text used in y-axis \
    label to reference experimental sample. Following `--exp_desig` type what \
    you'd like to read there instead of `experimental`.") 
parser.add_argument('-bd', '--base_desig', action='store', type=str, 
    default= 'wild\mathrm{-}type', help="Allows changing the text used in y-axis \
    label to reference wild-type or baseline sample. Following `--base_desig` \
    type what you'd like to read there instead of `wild-type`.") 
parser.add_argument("-svg", "--save_vg",help=
    "add this flag to save as vector graphics \
    (**RECOMMENDED FOR PUBLICATION***) instead of default png. Not default or \
    saved alongside default because file size can get large due to the large \
    number of points.",
    action="store_true")
parser.add_argument('-ac', '--advance_color', action='store', type=int, 
    default= '0', help="**FOR ADVANCED USE.*** Allows for advancing the color \
    selection iterator the specified number of times. The idea is it allows \
    the ability to control the color of the chromosome when specifying \
    a chromosome or scaffolds to plot so you could make the color match the \
    one used when all chromsome plotted if needed. Supply the number to \
    advance after the flag on the command line. For example, `-ac 4`.") 

#I would also like trigger help to display if no arguments provided because need at least one input file
if len(sys.argv)==1:    #from http://stackoverflow.com/questions/4042452/display-help-message-with-python-argparse-when-script-is-called-without-any-argu
    parser.print_help()
    sys.exit(1)
args = parser.parse_args()
annotaton_file = args.annotation
data_files_list = args.data_files_list
if len(data_files_list) == 1:
    sys.stderr.write("\nERROR: You need to specify at least two files for the data. At least one for wild-type(baseline) and at least one for the experimental sample.\n")
    sys.exit(1)
wt_num = args.wt_num
if wt_num is None:
    if len(data_files_list) % 2 == 0:
        wt_files = data_files_list[:int(len(data_files_list)/2)]
    else:
        sys.stderr.write("\nERROR: Since you provided an ueven number of data files, you need to specify how many of the provided data files correspond to wild-type(baseline) by providing `--wt_num` setting, such as `--wt_num 1`.\n")
        sys.exit(1)
else:
    if wt_num >= len(data_files_list):
        sys.stderr.write("\nERROR: Your `wt_num` value seems to high; there needs to be at least one for the experimental sample.\n")
        sys.exit(1)
    wt_files = data_files_list[:wt_num]
exp_files = [x for x in data_files_list if x not in wt_files]
# somewhat based on http://kitchingroup.cheme.cmu.edu/blog/2014/03/25/Deleting-multiple-elements-of-a-list/ 
# and https://stackoverflow.com/questions/4211209/remove-all-the-elements-that-occur-in-one-list-from-another

data_column = args.column
no_log = args.no_log
lines = args.lines
if args.chrs:
    if "," in args.chrs:
        limit_to_chrs = args.chrs.split(',')
    else:
        # means only one item
        limit_to_chrs = [args.chrs] #has to be a list for passing to Pandas `isin()` 
else:
    limit_to_chrs = args.chrs # will make `limit_to_chrs` as `None`
advance_color_increments = args.advance_color
display_smooth = args.smooth
no_limits = args.no_limits
exp_designation = args.exp_desig
baseline_designation = args.base_desig
save_vg = args.save_vg





###-----------------Actual Main portion of script---------------------------###

# ANNOTATION FILE ACCESSING AND GENOME DATAFRAME INITIAL PREPARATION
# open annotation file and make it a Pandas dataframe
sys.stderr.write("\n\
    Reading annotation file and getting data on genes and chromosomes...")
#determine if annotation is gff or gtf
if "gff" in annotaton_file.name.lower():
    col_names_to_apply = genome_annotation_fields_for_gff 
    column_types = column_types_for_gff

if "gtf" in annotaton_file.name.lower():
    col_names_to_apply = genome_annotation_fields_for_gtf 
    column_types = column_types_for_gtf

# read in annotation file
init_genome_df = pd.read_csv(
    annotaton_file, sep='\t', header=None, low_memory=True,
    names=col_names_to_apply, comment='#',dtype=column_types) # comment handling 
# added because I came across gtfs with a header that had `#`  at start of each 
# line. Others must have encountered same because I saw someone dealing with it 
# at https://github.com/shenlab-sinai/ngsplotdb/pull/2/files. I cannot use that 
# solution since I use Pandas read_csv function. (`read_table`) was 
# deprecated recently. dtypes added when speed and working with large files
# became an issue, see 
# https://github.com/fomightez/sequencework/issues/1#issuecomment-465760222
# When I tested timing lines using yeast data (gtf; 12 Mb) and 
# https://stackoverflow.com/a/14452178/8508004, I found it slightly faster
# (0.42 vs 0.50) with `low_memory=False`, and so that is why that is used. I 
# suspect the difference would be even starker with the 1.4 Gb human GTF. I only 
# ended up seeing it get this far with the because I used `sys.exit(1)` to stop 
# it after the read.
#(LATER: When just read of human gtf timed in a notebook with `%%time`, with 
# `low_memory=False` it took only 1 min 10s whereas it was 4min 44s when 
#`True`. That effort with human data was done running in Cyverse. Oddly, on
# Cyverse it turned out never to take that long again when `True`, usually
# disparity only about 40 seconds.)

#sys.stderr.write("...parsing genes...") # There is no point in this because I 
# found stderr , for reasons I don't understand, although have seen similar when
# working in notebooks, won't output after pandas read starts even though with 
# yeast gtf (12 Mb) that read is almost instantaneous (see timing above.) 
#

# Parse out gene_ids from attribute or group, i.e., 9th column in the annotation 
# file.

#init_genome_df = (init_genome_df[init_genome_df[init_genome_df.columns[-1]].
    #str.contains("gene_id")]) #for yeast and human this doesn't seem to 
    # remove anything and so there is no point trying to use it to limit to
    # pertinent rows.

init_genome_df["gene_id"] = init_genome_df.apply(extract_gene_ids, axis=1)


# Next want to end up with one entry per gene with the start and end 
# coordinates. I was originally doing this using the code in docstring below 
# but  efficiency became an issue when someone tried with human data. And
# I recalled learning appending can be very infficient, see 
# https://stackoverflow.com/a/31713471/8508004 and Tinkerbeast's comment at 
# https://stackoverflow.com/a/25376997/8508004 . So code after doesn't
# use `.append` and accomplishes the same outcome with more pythonic
# pandas-based steps.
'''
# copy each row to a new dataframe, unless gene already present. 
# This will give me unique gene_ids for each and I can make that index.
# Because it takes first occurence of each gene, it only has that as start and
# end. Then to get the full range of data for start and end for each gene, I can
# subset the initial dataframe on each gene_id and get the min and max and use
# those values to replace `start` and `end` for the new dataframe. For those
# on Crick strand, it will turn around the start, end information, but that is
# fine since just want an avg relative position and don't care about direction.
genome_df = pd.DataFrame(columns=init_genome_df.columns)
for i, row in init_genome_df.iterrows():
    if not any(genome_df.gene_id == row.gene_id):
        genome_df = genome_df.append(row)
genome_df = genome_df.set_index('gene_id')
for id in list(genome_df.index.values):
    sub_df = init_genome_df.loc[init_genome_df["gene_id"] == id]
    min_val = min(sub_df[["start","end"]].min()) # `sub_df["start","end"].min()` gives values for the two columns and so min() of that gives single value
    max_val = max(sub_df[["start","end"]].max())
    genome_df.loc[id, "start"] = min_val
    genome_df.loc[id, "end"] = max_val
# provide feedback on number of unique genes identified
sys.stderr.write("Information for {0} genes parsed...".format(len(genome_df)))
'''
# Use groupby and `.agg()` to get min and max. Then move the multi-index
# datafram produced to single index, where gene_id is the index, and the
# 'seqname' gets moved from hierarchical index to a column.
genome_df = init_genome_df.groupby(
    ["gene_id","seqname"]).agg({'start': min,'end': max}) 
genome_df = genome_df.reset_index(level=['seqname']) #based on 
# https://stackoverflow.com/a/20461206/8508004
# provide feedback on number of unique genes identified
sys.stderr.write("Information for {0} genes parsed.."
    ".".format(len(genome_df)))

# calculate average position
# genome_df["position"] = genome_df[["start","end"]].apply(np.mean, axis=1) # gives float and I'd prefer as integer
genome_df["position"] = genome_df.apply(calculate_position, axis=1)
# make a column of chrosomes as numbers, either converting from the string they
# would be by default (I think?) or converting from roman numerals. This will be
# used for sorting later
# First determine if chromosomes are numbers with X and Y (and others?) or if
# in the form of roman numerals
chromosomes_in_roman_num = False
# check if majority look like integers. If that is the case verify most are 
# valid roman numerals just to be sure.
genome_df['seqname'] = genome_df['seqname'].apply(str) # cast to string so 
# string methods like `.isdigit()` continue to work even when chromosomes are 
# actually numbers; faster way from 
# https://stackoverflow.com/questions/17950374/converting-a-column-within-pandas-dataframe-from-int-to-string/44008334
seqname_set = set(genome_df['seqname'].tolist())
chromosomes_in_roman_num = not bool(len([s for s in seqname_set if s.isdigit()]) > len(seqname_set)/2) #checks if most chromosomes seem to be digits and says they are roman numerals if that is false
if chromosomes_in_roman_num:
    most_valid_rom_numerals = bool(len([n for n in seqname_set if checkIfRomanNumeral(n)]) > len(seqname_set)/2)
    # provide feedback if don't seem to be roman numerals
    if not most_valid_rom_numerals:
        sys.stderr.write("***WARNING***The chromosomes seem to not be in numeric form, but most aren't valid roman numerals either.***WARNING***....")
    else:
        sys.stderr.write("The chromosomes appear to be in roman numeral form....")
else:
    sys.stderr.write("The chromosomes appear to be in numeric form....")
# Second, convert if `chromosomes_in_roman_num` otherwise just try to coerce string to integer, allowing not to coerce and not throw an error in case of the sex chromosomes
if chromosomes_in_roman_num:
    # try and convert each row but allow for non type change without error
    genome_df["chr_as_numeric"] = genome_df.apply(
        seqname_roman_to_numeric, axis=1)
else:
    genome_df["chr_as_numeric"] = genome_df.apply(
        seqname_string_to_numeric, axis=1)
longest_chr_or_scaffold = len(max(seqname_set, key=len))
# Prepare genome dataframe for accessing data by adding a column for relative 
# level and fill with 'NaN'
genome_df["level_val"] = np.nan




# ACCESSING EXPRESSION DATA
# Open each of the data files and collect level data per gene for wild-type and 
# experimental samples. 
# In cases for each set where, data provided for more than one replicate, 
# calculate mean and use that to calculate ratio of experimental to baseline
# for each gene.
sys.stderr.write("Parsing data files...")
baseline_dictionary = {}
experimental_dictionary = {}

baseline_dictionary = get_gene_expression(wt_files,baseline_dictionary)
experimental_dictionary = get_gene_expression(exp_files,experimental_dictionary)

# combine the data parsed (mean will still come out as first (and presumably only) value in the list one only one value so this calculation covers all cases)
baseline_mean_dictionary = {}
experimental_mean_dictionary = {}
for gene in baseline_dictionary:
    baseline_mean_dictionary[gene] = sum(baseline_dictionary[gene])/float(len(baseline_dictionary[gene]))
for gene in experimental_dictionary:
    experimental_mean_dictionary[gene] = sum(experimental_dictionary[gene])/float(len(experimental_dictionary[gene]))

'''
# combine the data parsed
baseline_mean_dictionary = []
if len(wt_files) > 1:
    # calculate mean and add that to the mean_dictionary
    for gene in baseline_dictionary:
        baseline_mean_dictionary[gene] = sum(baseline_dictionary[gene])/float(len(baseline_dictionary[gene]))
else:
    assert len(wt_files) == 1 (
    "There should be just one wild-type file at this point.")
    # add the first (and presumably only) value in the list to the mean_dictionary
    for gene in baseline_dictionary:
        baseline_mean_dictionary[gene] = baseline_dictionary[gene][0]
experimental_mean_dictionary = []
if len(exp_files) > 1:
    # calculate mean and add that to the mean_dictionary
    for gene in experimental_dictionary:
        experimental_mean_dictionary[gene] = sum(experimental_dictionary[gene])/float(len(experimental_dictionary[gene]))
else:
    assert len(exp_files) == 1 (
        "There should be just one experimental file at this point.")
    # add the first (and presumably only) value in the list to the mean_dictionary
    or gene in experimental_dictionary:
        experimental_mean_dictionary[gene] = experimental_dictionary[gene][0]
'''






# Calculate and add the relative expression ratio for each gene to the Pandas 
# dataframe.
sys.stderr.write("Combining genes and corresponding expression ratios...")
# deal with those that would cause division by zero errors when making log2 here
not_found_in_annotation = []
cause_div_by_zero = []
lines_processed = 0
data_entered = 0
for gene in baseline_mean_dictionary:
    #just to make sure no error thrown when ration calculation tried, only proceed if data on gene is in experimental_mean_dictionary too 
    if gene in experimental_mean_dictionary:
        if gene in genome_df.index:
            if baseline_mean_dictionary[gene] != 0.0 and ((not no_log and experimental_mean_dictionary[gene] != 0.0) or (no_log)):
                genome_df.loc[gene, "level_val"] = experimental_mean_dictionary[gene]/baseline_mean_dictionary[gene]
                data_entered += 1
            else:
                cause_div_by_zero.append(gene)
        else:
            not_found_in_annotation.append(gene)

# provide feedback on any genes from the data with no correspondence in the annotation
if not_found_in_annotation:
    sys.stderr.write("\nNote that data for {} genes was read but no corresponding annotation entry was found. Those genes are {!r}.".format(
        len(not_found_in_annotation), not_found_in_annotation))
    if data_entered != 0 and ((len(not_found_in_annotation)/data_entered)*100) > 3:
        sys.stderr.write(" Since that is less than 3% of the genes with expression data and so probably won't make much difference to the plot...")
    else:
        sys.stderr.write("***WARNING***...")
# provide feedback on any genes causing zero division error
if cause_div_by_zero:
    sys.stderr.write("\nNote that the value in the data for {} genes would trigger division by zero errors and so they were left out. Those genes are {!r}...".format(
        len(cause_div_by_zero), cause_div_by_zero))







# PREPARE GENOME DATAFRAME NOW HARBORING EXPRESSION DATA FOR PLOTTING
# if limiting to specific chromosomes or scaffolds, discard any other data
if limit_to_chrs:
    genome_df = genome_df.loc[genome_df["seqname"].isin(limit_to_chrs)]
# sort by position on chromosome
genome_df.sort_values(["position"], inplace=True, ascending=True) 
# sort by chromosome
genome_df.sort_values(["chr_as_numeric","position"], inplace=True, ascending=True) # found `genome_df.sort_values(["chr_as_numeric"], inplace=True, ascending=True)` alone after previous sort didn't work but this seemed to result in what I wanted in end
# make a dictionary of dictionaries with details of each chromsomes, 
# specifically length(approximate based on genes/features) and midpoint
# (to be used for tick marks later).
# not all assigned variables for the chromosomes_specs dictionary used here but
# also useful for generating a summary of assignments used & is small and could 
# be more useful down the road.
chr_specs = {}
xs_by_chr = [] #ported over from https://github.com/brentp/bio-playground/blob/master/plots/manhattan-plot.py
# sorting just above makes it easy to get last entry for each chromosome
grouped = genome_df.groupby('seqname', observed=True) #`observed=True` necessary
# because 'seqname' defined as categorical to get better ordering of human-style 
# chromosomes without any intervention. But without `observed=True` it uses all 
# the originally defined categoricals (chromosomes) as groupings and not just 
# ones in dataframe where subset based on `limit_to_chrs`.
previous_chr_last_x = 0
for chr, data_per_chr_df in grouped:
    chr_specs[chr] = {}
    chr_length = data_per_chr_df['end'].tolist()[-1]
    chr_midpoint = chr_length/2
    chr_specs[chr]["length"] = chr_length
    chr_specs[chr]["midpoint"] = chr_midpoint
    # next ones just for plotting adjacent the previous chromosome
    chr_specs[chr]["x_start"] = previous_chr_last_x
    x_midpoint = previous_chr_last_x + chr_midpoint
    chr_specs[chr]["x_midpoint"] = x_midpoint
    xs_by_chr.append((chr,x_midpoint))
    previous_chr_last_x = previous_chr_last_x + chr_length
#I THOUGHT THIS WOULD RESULT IN ORDER CURRENTLY IN DATAFRAME BUT IT DOESN'T. IF WERE ABLE TO HAVE IT WORK, IS IT EVEN NECESARY??#sorted_chr_set = set(genome_df['seqname'].tolist()) #should be order as established in SORTED genome_df; earlier set wasn't from the version sorted on chromosome

# filter out anything where "level_val" is `NaN`; waited to do this until after
# making the dictionary of chr_specs so could consider even genes or features 
# where no expression plotted as contributing to position information to keep
# width scale in plot closer to reality for each chromosome.
genome_df.dropna(subset=["level_val"], inplace = True)
# group by chromosomes and iterate making lists of x values that increase across
# all chromosomes and fills in corresponding y values and arranges colors.
# Note even though I iterated on a similar `grouped` by chromosome iterable 
# earlier, I couldn't yet capture x & y values for plot b/c had not yet removed 
# those with no expression values. Not DRY, but will better represent chromosome
# relative scale this way.
grouped_from_filtered = genome_df.groupby('seqname', observed=True) # Note that
# `observed=True` necessary because 'seqname' defined as categorical to get 
# better ordering of human-style chromosomes without any intervention. But 
# without `observed=True` it uses all the originally defined categoricals 
# (chromosomes) as groupings and not just ones in dataframe where subset based 
# on `limit_to_chrs`.
xs = []
ys = []
cs = []

colors = cycle(colors)
# handle advancing colors if adjusting based on user provided info
if advance_color_increments:
    for i in range(advance_color_increments): color = next(colors)
# prepare to collect data on per chromosome basis if lowess smoothing flag on
if display_smooth:
    data_by_chr = {}
previous_chr_last_x = 0
for chr, data_per_chr_df in grouped_from_filtered:
    chr_length = chr_specs[chr]["length"] # this may be larger than the final 
    # "end" position in the filtered group, & so would better reflect scale of 
    # each chromosome
    color = next(colors)
    this_chromosomes_xs = [previous_chr_last_x + position for position in data_per_chr_df['position'].tolist()]
    this_chromosomes_ys = [level_val for level_val in data_per_chr_df['level_val'].tolist()]
    assert min(this_chromosomes_xs) >= chr_specs[chr]["x_start"], (
    "x values for individual genes cannot be lower than the \
    `starting x value` for that chromosome.")
    assert max(this_chromosomes_xs) <= (
        chr_specs[chr]["x_start"] + chr_specs[chr]["length"]), ("x values for \
        individual genes cannot be greater than the sum of the `starting x \
        value` for that chromosome plus the length of that chromosome.")
    xs.extend(this_chromosomes_xs)
    ys.extend(this_chromosomes_ys)
    cs.extend([color] * len(data_per_chr_df))
    # collect pertinent data on per chromosome basis if lowess smoothing flag
    if display_smooth:
        data_by_chr[chr] = {}
        data_by_chr[chr]["xs"] = this_chromosomes_xs
        data_by_chr[chr]["ys"] = this_chromosomes_ys
    previous_chr_last_x = previous_chr_last_x + chr_length





# MAKE THE PLOT
# This follows the plotting approach of Brent Pedersen's `manhattan-plot.py`  
# closely, see https://github.com/brentp/bio-playground/blob/master/plots/manhattan-plot.py .

xs = np.array(xs)
ys = np.array(ys) if no_log else np.log2(ys)

plt.close()
plt.style.use(plot_style)
f = plt.figure()
#ax = f.add_axes((0.1, 0.09, 0.88, 0.85))
ax = plt.axes()

if title_prefix is not None:
    if limit_to_chrs:
        title = title_prefix + " ".join(limit_to_chrs)
    else:
        title = title_prefix + "genome"
    plt.title(title, fontsize=18)
# At first I could not get LATeX to work with the y-axis labels even though what I have in the commented out lines below between `$` works in both Jupyter notebooks markdown cells (put between `$$`) and inserted in place of the LATeX code from the tex_demo.py script at https://matplotlib.org/users/usetex.html that use `plt.plot()`

'''
if no_log:
    ax.set_ylabel('$\frac{\text{experimental\ level}}{\text{wild-type\ level}}$')
else:
    ax.set_ylabel('$\log 2\left(\frac{\text{experimental\ level}}{\text{wild-type\ level}}\right)$',
          fontsize=16)
'''
# Then I found https://stackoverflow.com/questions/23824687/text-does-not-work-in-a-matplotlib-label says that the issue is that matplotlib uses a different rendering engine, MathText. Seems for `\text{}` want obscure `\mathrm{}`. Plus if concatenating variable, need `r` again in front of string after the final plus sign in a concatenation command.
if no_log:
    ax.set_ylabel(r'$\frac{\mathrm{'+ exp_designation +r'\ level}}{\mathrm{'+ baseline_designation +r'\ level}}$',
          fontsize=16)
else:
    ax.set_ylabel(r'$\log 2 \left(\frac{\mathrm{'+ exp_designation +r'\ level}}{\mathrm{'+ baseline_designation +r'\ level}}\right)$',
          fontsize=16)
# Below keeps ylabels plain for if LATeX failing
'''
if no_log:
    ax.set_ylabel('experimental level/wild-type level')
else:
    ax.set_ylabel('log2(experimental level/wild-type level)')
'''
if lines:
    ax.vlines(xs, [0], ys, colors=cs, alpha=0.5) # Despite change noted here still doesn't work when log2 used because of the `divide by zero encountered in log2` issue that makes infinites===> `0` to `[0]` based on example at http://matplotlib.org/1.2.1/examples/pylab_examples/vline_demo.html
else:
    ax.scatter(xs, ys, s=12, c=cs, alpha=0.8, edgecolors='none')

# plot 0.05 line after multiple testing.
#ax.axhline(y=-np.log10(0.05 / len(genome_df)), color='0.5', linewidth=2)
plt.axis('tight')
#plt.xlim(0, xs[-1])
if no_log or no_limits or all(-y_cutoff <= n <= y_cutoff for n in ys):
    #plt.ylim(ymin= None, ymax= None) # necessary?
    pass # see comment on above line
else: 
    plt.ylim(ymin=-y_cutoff, ymax=y_cutoff)
    # catch out of bounds points for plotting in a manner to indicate out of 
    # bounds of limits used to avoid compressing important range. This approach
    # is styled on how DESeq2 plotMA handles out of bounds points.  Found to 
    # easily control rotation of the marker in plot call, best to split.
    # prepare to catch points too high
    xs_out_of_bounds_hi = []
    ys_out_of_bounds_hi = []
    cs_out_of_bounds_hi = []
    # prepare catch points too low
    xs_out_of_bounds_lo = []
    ys_out_of_bounds_lo = []
    cs_out_of_bounds_lo = []
    offset = 0.055 #so not cut off at edge
    for indx, pt in enumerate(ys):
        if pt > y_cutoff:
            ys_out_of_bounds_hi.append(y_cutoff - offset)
            xs_out_of_bounds_hi.append(xs[indx])
            cs_out_of_bounds_hi.append(cs[indx])
        elif pt < -y_cutoff:
            ys_out_of_bounds_lo.append(-y_cutoff + offset)
            xs_out_of_bounds_lo.append(xs[indx])
            cs_out_of_bounds_lo.append(cs[indx])
    oobs_marker_sz = 25 # out of bounds marker size
    oobs_width = 1 # out of bounds marker linewwidth
    rotation_for_hi = 0
    rotation_for_lo = 180
    # "Plot" the out-of-bounds points
    plt.scatter(xs_out_of_bounds_hi, ys_out_of_bounds_hi, marker=(3, 0, rotation_for_hi), s=oobs_marker_sz, linestyle='solid',linewidth=oobs_width, facecolors='None', edgecolors=cs_out_of_bounds_hi) # see https://stackoverflow.com/questions/4143502/how-to-do-a-scatter-plot-with-empty-circles-in-python; use `facecolors` for scatter and markerfacecolor for `plt.plot`
    plt.scatter(xs_out_of_bounds_lo, ys_out_of_bounds_lo, marker=(3, 0, rotation_for_lo), s=oobs_marker_sz, linestyle='solid',linewidth=oobs_width, facecolors='None', edgecolors=cs_out_of_bounds_lo) # see https://stackoverflow.com/questions/4143502/how-to-do-a-scatter-plot-with-empty-circles-in-python; use `facecolors` for scatter and markerfacecolor for `plt.plot`
    sys.stderr.write(
        "\n***Notice:***The {} points beyond the bounds of y-axis are drawn as open triangles at the edge; a limit was imposed to avoid extreme values compressing the typically important range; run with `--no_limits` or `--no_log` to see these accurately."
        .format(len(xs_out_of_bounds_hi) + len(xs_out_of_bounds_lo)))
#if ymax is not None: plt.ylim(ymax=ymax)
size_for_xlabels = 8.5
longest_chr_or_scaffold = len(max(seqname_set, key=len))
if limit_to_chrs is None:
    if longest_chr_or_scaffold > limit_before_rotate:
        plt.xticks(
            [c[1] for c in xs_by_chr], [c[0] for c in xs_by_chr], 
            rotation=-90, size=size_for_xlabels)
    else:
        plt.xticks(
            [c[1] for c in xs_by_chr], [c[0] for c in xs_by_chr], size=size_for_xlabels)
else:
    # If only handling a few chromosomes or scaffolds don't bother checking if name exceeds the length. 
    # Deciding what is "few" there will be the same integer used to decide what length of characters
    # is too great to not rotate. This is done just to make it so another variable isn't needed.
    if (len(limit_to_chrs) > limit_before_rotate) and (longest_chr_or_scaffold > limit_before_rotate):
         plt.xticks(
            [c[1] for c in xs_by_chr], [c[0] for c in xs_by_chr], 
            rotation=-90, size=size_for_xlabels)
    else:
        plt.xticks(
            [c[1] for c in xs_by_chr], [c[0] for c in xs_by_chr], size=size_for_xlabels)



# add lowess curve fit to each chromosome if `smooth` flag
if display_smooth:
    chr_deviating_from_baseline = []
    for chr in data_by_chr:
        lowess_ys = lowess(
            data_by_chr[chr]["ys"], data_by_chr[chr]["xs"], 
            return_sorted=False) if no_log else lowess(
            np.log2(data_by_chr[chr]["ys"]), data_by_chr[chr]["xs"], 
            return_sorted=False)
        plt.plot(
            data_by_chr[chr]["xs"],lowess_ys,'gray',linewidth=12, alpha=0.55)
        # assess if chromosome/scaffold deviates from baseline
        if deviates_from_baseline(lowess_ys):
            chr_deviating_from_baseline.append(chr)
    # provide feedback if deviation from norm noted
    if chr_deviating_from_baseline:
        sys.stderr.write(
            "\nAneuploidy at the chromosome or scaffold level is suggested for {}; examine further.".format(" & ".join(chr_deviating_from_baseline)))


output_file_name = generate_output_file_name(exp_files[0], suffix_for_saving_result)
if save_vg:
    plt.savefig(output_file_name[:-4]+".svg", orientation='landscape') # FOR VECTOR GRAPHICS; useful if merging into Adobe Illustrator. Based on https://neuroscience.telenczuk.pl/?p=331 ; I think ReportLab also outputs SVG?
    sys.stderr.write("\n\nPlot image saved to: {}\n".format(output_file_name[:-4]+".svg"))
else:
    plt.savefig(output_file_name)
    sys.stderr.write("\n\nPlot image saved to: {}\n".format(output_file_name))
    # plt.savefig(output_file_name[:-4]+".svg")
    # sys.stderr.write("\n\nPlot image saved to: {}\n".format(output_file_name[:-4]+".svg"))
    # plt.savefig(output_file_name[:-4]+".pdf", orientation='landscape') # UNFORTUNATELY DOES NOT PRODUCE VECTOR GRAPHICS, unlike ReportLab's pdf output; USE SVG for that and the make PDF later.
    #plt.show()


#*******************************************************************************
###-***********************END MAIN PORTION OF SCRIPT***********************-###
#*******************************************************************************
